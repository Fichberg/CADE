\documentclass[11pt]{report}
\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage[a4paper,margin={1in}]{geometry}
\usepackage{color}
\usepackage{textcomp}
\usepackage[bottom]{footmisc}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage[table]{xcolor}
\usepackage{caption}
\usepackage{titlesec}
\usepackage{color,soul}
\usepackage{varwidth}

\newcommand{\quotes}[1]{``#1''}

\titleformat{\section}{\normalfont\Large\bfseries}{\thesection}{1em}{}[{\titlerule[0.4pt]}]

\definecolor{fill}{rgb}{0.18, 0.31, 0.31}
\definecolor{strong}{rgb}{0.5, 1.0, 0.0}
\definecolor{moderate}{rgb}{0.24, 0.82, 0.44}
\definecolor{weak}{rgb}{0.99, 0.05, 0.21}

\pagestyle{fancy}
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\fancyhf{}
\fancyhead[RE]{\chaptername~\thechapter}
\fancyhead[LO]{\leftmark}
\rhead{\chaptername \enspace \thechapter}
\cfoot{\thepage}

\setcounter{secnumdepth}{3}

\begin{document}

\begin{center}
  \thispagestyle{empty}
  {\LARGE \textbf{Universidade de São Paulo}}
  \vspace*{10px}

  {\LARGE \textbf{Instituto de Matemática e Estatística (IME-USP)}}
  \vspace*{150px}

  {\Large \textbf{Reconhecimento de Entidades Mencionadas para Notificações de Processos Judiciais do Conselho Administrativo de Defesa Econômica}}
  \vspace*{100px}

  {\Large Aluno: Renan Fichberg}

  \vspace*{1px}
  {\Large Orientador: Prof. Dr. Marcelo Finger}

  \vspace*{150px}
  {\large Monografia de Conclusão de Curso realizado para a disciplina}

  \vspace*{1px}
  {\large MAC0499 - Trabalho de Formatura Supervisionado}

  \vspace*{100px}
  {\large São Paulo, novembro de 2016}
\end{center}

\pagebreak
\thispagestyle{empty}
\chapter*{Agradecimentos}
\markboth{UNNUMBERED CHAPTER}{}

\indent\indent Este trabalho, apesar de ter apenas um autor, possui muito das experiências e conhecimento que acumulei ao longo
do curso de Bacharelado em Ciência da Computação e, reconheço, não seria possível realizá-lo não fosse o aprendizado e o incentivo que tive, de várias
pessoas com quem convivi não apenas na universidade, mas fora dela também. Destaco, a seguir, algumas pessoas com quem tive a chance de aprender
bastante para chegar até o presente momento:

Primeiramente, aos meus pais Eloy Fichberg e Regina Célia de Oliveira Pinto e aos meus irmãos Felipe Fichberg e Leone Fichberg, que sempre foram
as pessoas mais presentes na minha vida, me incentivando a seguir adiante em todos os momentos.

Em seguida, aos meus grandes amigos que acompanharam a minha trajetória de perto, Eduardo Gromatzky Feder e Gabriel Engel Pesso, que sempre foram companheiros
em todos os momentos.

Aos meus colegas e amigos de curso Maurício Cardoso, Luiz da Silva Armesto, Renato Cordeiro Ferreira, Pedro de Carvalho Rogrigues, João Marco Maciel da Silva,
Gervásio Santos, Renato Massao, Yara Grassi Gouffon, Rafael Raposa, Lucas Hiroshi Hayashida, Victor Sanches Portella, Luciana Abud, Vinícius Vendramini, Ruan Costa,
Vinícius Bitencourt Matos e tantos outros que percorreram juntos comigo essa trilha e sempre se mostraram dispostos a ajudar.

Aos meus colegas e amigos do Mezuro, Rafael Reggiani Manzo, Diego Araújo Martinez Camarinha, Fellipe Souto Sampaio, Heitor Reis Ribeiro, Guilherme Rojas, Alessandro Palmeira e
Daniel Paulino Alves, que sempre tinham algo de novo a ensinar.

Aos meus grandes amigos do colégio, Jonathan Schiriak, Allon Rozansky, Aaron Zarenczanski e Walter Caspari, pelos bons momentos, eventuais apoios e conselhos.

Aos colaboradores deste trabalho, William Collen, Kemil Raje Jarude e o meu orientador Prof. Dr. Marcelo Finger, por toda a paciência que tiveram com as minhas tantas dúvidas e
sugestões de estratégias e ferramentas para solucionar os problemas que foram surgindo.

E finalmente, a todos os professores que tive a oportunidade de conhecer e aprender algo. Todos foram essenciais para a minha trajetória.

\pagebreak
\thispagestyle{empty}
\chapter*{}
\markboth{UNNUMBERED CHAPTER}{}

\vspace*{\fill}
\textit{\quotes{The voice that navigated was definitely that of a machine, and yet you could tell that the machine was a woman, which hurt my mind a little. How can machines have genders? The machine also had an American accent. How can machines have nationalities? This can't be a good idea, making machines talk like real people, can it? Giving machines humanoid identities?}}
\begin{flushright} - Matthew Quick, The Good Luck of Right Now \end{flushright}
\vspace*{\fill}

\pagebreak
\thispagestyle{empty}
\chapter*{Resumo}
\markboth{UNNUMBERED CHAPTER}{}

\indent\indent O Conselho Administrativo de Defesa Econônima (CADE) é um orgão independente que reporta ao Ministério da Justiça e possui como missão garantir ao máximo a livre
concorrência de mercado em todo o território Brasileiro e realiza as suas funções legais de acordo com a Lei Nº 12.529/2011\footnote[1]{Acesso à Informação: Conheça o CADE}.
O CADE dispõem de uma base de dados bastante extensa, com processos judiciais de vários tipos distintos datados do ano de 1980 até os dias atuais e mais de 100 tipos diferentes de
documentos, desde formulários, notificações de processos e cópias escaneadas de documentos diversos até arquivos de áudio e vídeo.

O trabalho foi divido em duas partes distintas: a primeira se constituiu de explorar parte dos vários processos judiciais presentes na base de dados pública do CADE relacionados a Atos de
Concentração com finalísticos Sumário ou Ordinário e montar um Córpus com os tipos de documentos que foram julgados pertinentes em primeira análise. Em seguida, a partir de anotações
manuais de entidades mencionadas e seus relacionamentos sobre o Córpus construído, identificar automaticamente as entidades nos processos judiciais futuros que possam ser relevantes a classificação
final entre os dois tipos de rito: Sumário ou Ordinário. A segunda parte, por sua vez, constitue-se da classificação do processo judicial em um dos ritos mencionados por meio de
algoritmos de Aprendizado de Máquina, considerando as entidades que foram encontradas de forma automatizada nos documentos do processo em questão.

Este trabalho trata especificamente da primeira parte e serão aqui abordados assuntos relacionados a ela, tais como Processamento de Linguagem Natural, Reconhecimento de Entidades
Mencionadas e algumas ferramentas de \textit{software} que foram usadas para solucionar o problema em questão. A segunda parte, que infelizmente não foi desenvolvida por falta de tempo,
será discutida menos detalhadamente no capítulo 7, seção 7.2.1 - Aprendizado de Máquina.

Por fim, além destes conteúdos, também serão compartilhados experimentos e resultados obtidos por meio de validação cruzada com o Córpus desenvolvido, junto de possíveis estratégias que
foram aprendidas ao longo do trabalho que poderiam, talvez, melhorar a precisão e a corretude das anotações.

\pagebreak
\thispagestyle{empty}
\chapter*{Abstract}
\markboth{UNNUMBERED CHAPTER}{}

\indent\indent The Administrative Council for Economic Defense (CADE) is an independent agency reporting to the Ministry of Justice and has as mission to ensure to the maximum the free
market competition over the entirety of the Brazilian territory and performs its legal functions according to the Law Nº 12.529/2011\footnote[2]{Acesso à Informação: Conheça o CADE}.
The CADE owns an extense enough database, with judicial processes of many distinct types dated from the year of 1980 to the present days and over 100 types of different documents,
from formularies, process notifications and scanned copies of diverse documents to audio and video files.

The work was divided in two distinct parts: the first one constituted of exploring part of the many judicial processes within the public database owned by CADE related to Concentrations
Acts with final procedure being either \quotes{Sumario} or \quotes{Ordinario} and build a Corpus with the document types that were considered pertinent in first analysis. After that,
considering manual annotations of named entities and its relationships done over the built Corpus, identify automatically the entities in the future judicial processes that can be relevant
to the final classification between the two types of rite: \quotes{Sumario} or \quotes{Ordinario}. The second part constitutes of the classification of the judicial process in one of
the mentioned rites through the use of Machine Learning algorithms, considering the entities that were found automatically in the documents of the given process.

This work covers specifically the first part and will be discussed here subjects related to it, like Natural Language Processing, Named Entity Recognition and some of software tools that
were used to solve the introduced problem. The second part, which unfortunately was not developed duo to the lack of time, will be briefly discussed in chapter 7,
section 7.2.1 - Aprendizado de Máquina.

At last, in addition to these contents, will also be shared experiments and results obtained through the use of cross validation with the created Corpus, along with possible strategies that
were learned throughout this project that could, maybe, increase the precision and correctness of the annotations.

\pagebreak
\thispagestyle{empty}
\chapter*{Glossário de Siglas}
\markboth{UNNUMBERED CHAPTER}{}

\indent\indent As siglas descritas a seguir aparecem em partes diversas desta monografia. Confira abaixo
os seus significados:

\vspace*{20px}

\noindent AC - Ato de Concentração

\vspace*{8px}
\noindent AM - Aprendizado de Máquina

\vspace*{8px}
\noindent CADE - Conselho Administrativo de Defesa Econômica

\vspace*{8px}
\noindent DOU - Diário Oficial da União

\vspace*{8px}
\noindent IA - Inteligência Artificial

\vspace*{8px}
\noindent PLN - Processamento de Linguagem Natural

\vspace*{8px}
\noindent REM - Reconhecimento de Entidades Renomadas

\vspace*{8px}
\noindent RI - Recuperação de Informações

\pagebreak
\thispagestyle{empty}
\chapter*{Índice}
\markboth{UNNUMBERED CHAPTER}{}

\pagebreak
\chapter{Introdução}
\indent\indent Neste primeiro capítulo será abordado um pouco da motivação para o desenvolvimento deste trabalho bem como os seus objetivos e o problema envolvido.
Todo e qualquer conteúdo mais técnico mencionado aqui será melhor explorado nos capítulos sucessivos, desde assuntos relacionados a áreas da computação, tais como
Reconhecimento de Entidades Mencionadas, até o funcionamento do Conselho Administrativo de Defesa Econômica, seus processos e a sua base de dados. Assim sendo, o
leitor não deve se preocupar com eventuais dúvidas técnicas que possam surgir com a leitura deste capítulo meramente introdutório.

\section{Motivação}
\indent\indent O tema do projeto é atraente uma vez que está diretamente ligado à realidade da nossa sociedade. O CADE tem um papel
fundamental para manter a concorrência de mercado entre competidores de todos os portes, atuando como um orgão regulador legal. Sua existência é
particularmente importante para dar alguma garantia aos pequenos negócios de não serem engolidos por \textit{players} veteranos, que
já atuam em determinado mercado há mais tempo e, portanto, já dominam fatias consideráveis do público de interesse.

É conhecido também o fato de que os processos judiciais tendem a ser demorados e mesmo que os Atos de Concentração tratados pelo CADE, objetos de estudo deste
trabalho, sejam mais rápidos quando comparados a outros de diferente natureza, tentar torná-los ainda mais rápidos definitivamente é algo bem vindo, uma vez que
tais processos judiciais podem demorar até seis meses para terem um tipo de rito escolhido.

A idéia, portanto, é justamente buscar formas de automatizar os processos em andamento de tal forma que exista um ganho tanto para o CADE quanto para a sociedade.
Se tais processos pudessem ser acelerados, em sua totalidade ou partes do \textit{pipeline} envolvido na análise, futuramente a mesma solução poderia ser replicada
para resolver problemas similares com outros tipos de processos judiciais ou mesmo em outras áreas do conhecimento.

\subsection{Retorno}

\indent\indent Para o CADE, isso representaria a possibilidade de resolver mais processos em um mesmo intervalo de tempo, e para organizações ou mesmo cidadãos isso representaria
terem uma resposta mais rápida para planejarem as suas próximas ações. Em especial, é importante ressaltar que estamos lidando com o mercado, que é uma
entidade abstrata muito volátil, isto é: os mercados, de um modo geral, são flutuantes, de tal forma que a sua capacidade de se transformar é altíssima.
Um dado mercado pode estar em alta em um mês e em queda no mês seguinte. Devido em grande a parte globalização, mercados constituem entidades de difícil previsão
mesmo para \textit{experts} em economia.

À luz do que foi dito, portanto, quanto antes uma resposta for obtida, melhor será, já que ela teoricamente será mais fiel a configuração do mercado no momento da petição.

\section{Problema}

\indent\indent Dado um conjunto de processos judiciais com ritos conhecidos, queremos buscar saber em quais ritos os processos futuros se encaixarão. Temos dois tipos de classes possíveis para os ritos:
Ordinário e Sumário. Desta forma, este é claramente um problema de classificação binária e já existem maneiras conhecidas de resolvê-lo eficientemente a partir
de técnicas e algoritmos clássicos de AM.

Para conseguirmos desempenhar esta função, porém, é necessário estudarmos as especificidades do problema proposto e, em particular e principalmente,
do tipo de dados com que estamos lidando. Informações com relações a isso serão tratadas no capítulo 2 - O Conselho Administrativo de Defesa Econômica (CADE), na seção 2.2 - Base de Dados Pública.
Note que esta etapa é essencial para garantirmos não apenas uma maior eficiência na classificação final, mas também que o algoritmo está sendo treinado sobre
documentos totalmente fiéis à realidade.

Acerca do então exposto, surge naturalmente um segundo problema do qual o nosso \textit{approach} por AM irá depender diretamente: construir um Córpus para servir de modelo de
treinamento para identificar entidades chaves que podem ser determinantes no julgamento da classe do rito de um futuro processo.

Assim, uma das possibilidades que surge é usar REM para identificar tais entidades e, a partir destas, buscar alguma relação entre as entidades encontradas e um dos tipos de rito, com
base nos padrões que foram aprendidos a partir do Córpus de treinamento criado com processos antigos, presentes na base de dados pública do CADE. Focamos
a nossa atenção, portanto, em primeiramente resolver o problema da construção do Córpus para treinamento.

\section{Objetivos}

\indent\indent O principal objetivo deste trabalho foi estudar os ACs analisados pelo CADE para poder então, criar um Córpus de treinamento e a partir deste classificar
o AC em um dos ritos. Infelizmente, conforme já mencionado no Resumo, o escopo acabou revelando-se grande demais para o tempo disponível, e portanto teve de ser reduzido
ao primeiro problema. Mais sobre isso será discutido no capítulo 7, seção 7.1 - Dificuldades Encontradas.

Ainda, houve também um estudo do próprio funcionamento do CADE para entender mais sobre o problema e, em particular, um estudo voltado para a sua coletânea de processos
armazenada na sua extensa base de dados pública com o intuito de identificar os tipos de documentos que poderiam ser mais pertinentes à análise dos processos no que diz respeito
à classificação final do rito e também à forma que tais processos deveriam ser tratados para que fossem extraídas destes informações relevantes. Todo este conteúdo pode ser encontrado no
capítulo 2 - O Conselho Administrativo de Defesa Econômica (CADE).

Como objetivo também existiu a necessidade de estudar assuntos relacionados a AI, tais como PLN e REM, que serão abordados nos capítulos 3 e 4, respectivamente.
Ademais, foram estudadas ferramentas de \textit{software} que trabalham com PLN e REM: OpenNLP e o BRAT. Mais será dito sobre elas no capítulo 5, em suas
respectivas seções. Nestas seções será apresentado um estudo de como funcionam as funcionalidades usadas destas ferramentas e também como tais ferramentas foram
utilizadas para que os resultados apresentados no capítulo 6 - Resultados fossem alcançados.

Finalmente, foi estudado a partir da técnica estatística de validação cruzada o desempenho do Córpus criado e os tipos de erros que surgiram no processo de geração automatizada
de anotações de entidades mencionadas a partir do modelo de treinamento do Córpus, de tal forma que foram percebidas algumas boas práticas com relação ao uso destas ferramentas
para aumentar a eficácia e a precisão das marcações. Tais percepções serão comentadas, também, no capítulo 6 - Resultados.

\pagebreak
\chapter{O Conselho Administrativo de Defesa Econômica (CADE)}

\indent\indent Neste capítulo serão abordados assuntos relacionados ao CADE, aos Atos de Concentração que devem ser legalmente submetidos a ele e à base de dados pública que ele possui e
que contém tais processos judiciais. Sobre o CADE, será exposto um pouco da sua história e da sua função, para em seguida falarmos sobre o que são os ACs que cabem à sua competência
a análise e, finalmente, sobre a base de dados pública que foi usada para obter os Atos de Concentração que compõem o Córpus construído, posteriormente usado para treinarmos um modelo
que busca entidades mencionadas de forma automatiza. Mais informações sobre o Córpus serão abordadas no capítulo 3 - Processamento de Linguagem Natural - PLN e as suas entidades mencionadas no capítulo 4 - Reconhecimento de Entidades Mencionadas.

\section{Quem é o CADE?}

\indent\indent Criado pela Lei n° 4.137/62 como um orgão do Ministério da Justiça, o CADE hoje é uma autarquia em regime especial com jurisdição em todo o território nacional. Inicialmente,
era da responsabilidade do Conselho a fiscalização da gestão econômica e do regime de contabilidade das empresas, atraves da Lei n° 8.884/1994, o CADE transformou-se em uma
autarquia vinculada ao Ministério da Justiça.

Tal Lei definia as atribuições do CADE e de outros órgãos que formavam juntos com o Conselho Administrativo de Defesa Econômica o Sistema Brasileiro de Defesa da Concorrência e tinham
como missão garantir a política de defesa da livre concorrência em todo o território nacional. O CADE, em particular, era responsável pelo julgamento dos processos administrativos
que tinham relação com condutas anticompetitivas e também por apreciar Atos de Concentração, tais como aquisições, fusões, \textit{joint ventures} e outros que fossem submetidos
à sua aprovação.

Com a entrada da Lei nº 12.529/2011 em maio de 1012, esta uma nova Lei de Defesa da Concorrência, houve uma reestruturação do Sistema Brasileiro de Defesa da Concorrência e a política
da qual ele era encarregado, de defesa da concorrência, passou por mudanças significativas. Em especial, pela nova legislação, o CADE passou a ser responsável por competências até
então dos outros órgãos do Sistema Brasileiro de Defesa da Concorrência: instruir processos administrativos de apuração de infrações à ordem econômica e também de processos de análise
de Atos de Concentração. Ainda sobre a Lei nº 12.529/2011, a principal mudança introduzida consistia na exigência de submissão
prévia ao CADE de fusões e aquisições de empresas que podem proporcionar efeitos anticompetitivos no mercado, algo que no período anterior a esta Lei poderia ser feito depois destas
operações serem consumadas. Para o CADE, passou a existir então um prazo máximo de dozentos e quarenta (240) dias para análise das operações, prorrogáveis por mais noventa (90) dias
em casos de operações demasiadamente complexas.

Estruturalmente, com a Lei nº 12.529/2011 em vigor, tambem houveram mudanças: o CADE passou a ser constítuido pelo Tribunal Administrativo de Defesa Econômica, pelo Departamento de
Estudos Econômicos e pela Superintendência-Geral. A esta última cabe desempenhar no novo sistema grande parte das funções realizadas pelos outrora pelos órgãos que compunham junto
ao CADE o Sistema Brasileiro de Defesa Econômica antes da entrada da nova Lei de meio de 2012, tais como a investigação e a instrução de processos de repressão ao abuso do poder
econômico e a análise dos atos de concentração\footnote[3]{Acesso à Informação: Histórico do CADE}.

\section{Atos de Concentração Econômica}

\indent\indent Os Atos de Concentração Econômicas são caracterizados por operações que envolvem duas ou mais empresas independentes, conforme descrito no artigo 90 da Lei 12.529/2011. Tais operações
podem ser aquisições de controle ou incorporações de uma ou mais empresas por outras ou ainda a celebração de contratos associativos, consórcios ou \textit{joint ventures} entre duas
empresas ou mais.

\subsection{Operações}

\indent\indent São as operações, aliadas ao faturamento bruto anual ou volume de negócios no Brasil dos agentes econômicos envolvidos, que caracterizam a necessidade de existência dos
Atos de Concentração analisados pelo CADE. Quando o faturamento de uma das empresas envolvidas atinge o patamar mínimo de R\$ 750 milhões e o de uma outra, também envolvida na operação,
de pelo menos R\$ 75 milhões.

Considerando esta informação, é particularmente interessante que a aplicação desenvolvida saiba identificar as operações de um dado processo, especialmente
pela razão de que certas operações tendem a seguir mais um ou outro tipo de rito. É relevante ressaltar a observação, no entanto, que o tipo de operação não é uma condição suficiente
para identificar o tipo de rito, mas é um bom indicativo para buscarmos o mais provável\footnote[4]{Perguntas frequentes sobre Atos de Concentração Econômica}. Seguem abaixo
os possíveis tipos de operações que um AC pode ter:

\begin{itemize}
  \item \textbf{Fusão}: são caracterizadas pela união de duas ou mais empresas distintas para formar um novo agente econômico único.
  \item \textbf{Incorporação}: são caracterizadas pelo ato de uma ou mais empresas incorporar total ou parcialmente outras empresas dentro de uma mesma pessoa jurídica,
  de tal forma que o incorporado desaparece como pessoa jurídica, mas o incorporador mantém a sua identidade jurídica após a operação.
  \item \textbf{Aquisição}: são caracterizadas pelo ato de uma empresa adquirir o controle total ou parcial da participação acionária de outra empresa.
  \item \textbf{\textit{Joint venture}}: são caracterizadas pela criação de uma nova empresa a partir da associação entre duas ou mais empresas, de tal forma
  que as empresas que se associaram mantém normalmente suas identidades jurídicas pós operação.
\end{itemize}

\section{Base de Dados Pública}

\indent\indent O CADE possui uma base de dados\footnote[5]{Base de Dados Pública do CADE: Pesquisa Processual} com processos datados desde 1980 até os dias atuais, de tal forma que
para uma pessoa que não sabe ao certo o que está procurando facilmente pode se perder em meio a tantos tipos de processos. Para nós, porém, eram relevantes apenas
os tipos de processo \quotes{Finalístico: Ato de Concentração Ordinário} e \quotes{Finalístico: Ato de Concentração Sumário}, uma vez que foram os objetos de estudo deste trabalho.

Além dos tipos de processo, há outras informações que podem alimentar o sistema de recuperação de informação para que encontremos o que buscamos, tais como buscar um processo pelo
seu número ou dentro de um determinado período cronológico. Uma vez selecionado um dos tipos de processo que nos é relevante (um dos Atos de Concentração mencionados no parágrafo
anterior), é importante identificarmos os tipos de documentos que nos são relevantes para sabermos onde buscarmos as informações que precisamos.

A lista de tipos de documentos é deveras extensa e para alguém que desconhece o tipo de informação que está contido em cada um destes tipos de documentos, descobrir pode ser uma tarefa
bastante demorada. Precisamos, portanto, de alguma heurística para encontrarmos tipos de documentos que sejam potenciais candidatos a serem considerados de alta relevância para nós.

\subsection{Heurística de Seleção de Tipos de Documentos}

\indent\indent Queremos descobrir, dentre os mais de 100 diferentes tipos de documentos presentes na base de dados, aqueles que devem
ter as informações mais pertinentes para nós analisarmos os dados e tentarmos descobrir em qual rito determinado futuro processo será classificado.
Ignorando os tipos de documentos por um instante e acessando os diferentes Atos de Concentração que aparecem em uma pesquisa \quotes{crua} (isto é, com apenas um dos tipos de
processo selecionado), comparando-os um a um, é fácil de identificar que a maioria dos ACs, salve pouquíssimas exceções que provavelmente constituem em processos confidenciais,
possuem os tipos de documentos \quotes{Notificação}, \quotes{Formulário de Notificação} e \quotes{Publicação no DOU}.

Notavelmente, tais tipos de documentos, de acordo com as informações presentes na base de dados, sempre estão entre os primeiros documentos submetidos no instante em que um
Ato é dado como público. Para nós, o instante em que um AC é dado como público tem o mesmo efeito de encará-lo como inicializado, uma vez que não temos qualquer acesso
a documentos confidenciais, e portanto nada podemos inferir sobre eles.
Desta forma, chegamos à seguinte heurística para termos um ponto de partida e selecionarmos os tipos de documentos potencialmente mais interessantes, descrita abaixo:

\begin{enumerate}[label=\textbf{\arabic*.}]
\item Buscamos documentos que frequentemente \quotes{abrem} um Ato de Concentração.
\item Olhamos uma quantidade razoável de processos, digamos 50, e vemos em quantos deles tais documentos estão presentes
\item Supomos que tais documentos não são específicos a um AC e portanto devem ter as informações necessárias para que um novo Ato seja consolidado.
\item Como todo Ato obrigatoriamente segue um dos dois tipos de rito, as informações necessárias devem estar presente nos tipos de documentos selecionados.
\end{enumerate}

O item \textbf{1} da heurística é particularmente importante pois ele encapsula todo o objetivo da nossa aplicação: \textit{não queremos apenas identificar o mais provável tipo de rito
de um determinado Ato de Concentração, mas queremos fazer isso com o mínimo possível de informações}, ou seja: quanto menor o número de análises forem
necessárias por parte do CADE para chegar a uma conclusão relacionada ao rito, melhor.

Está idéia está diretamente relacionada ao \textit{pipeline} mencionado no capítulo 1 - Introdução, seção 1.1 - Motivação. Suponhamos aqui para ilustrar a idéia do
\textit{pipeline} de análise que um determinado AC pode ter no máximo \textit{n} fases $F_i$ e que $F_1$ e $F_n$ sejam suas fases inicial e final, respectivamente.
Suponhamos ainda que existam vários tipos de documentos $D_j$ que podem fazer parte do AC, mas que certos documentos só podem aparecer em uma fase $F_i$ específica.
Diremos que o valor $V_j$ de um dado documento $D_j$ é tão maior quanto menor for o valor de \textit{i}, para $i = 1, 2, 3 ... n$ e que $V_i \in [0, 1]$ de tal
forma que $V_1 = 1$ é o valor máximo de um documento e $V_n = 0$ o valor mínimo.
Consideremos, finalmente, o AC de \textit{n} = 5 fases composto dos 10 documentos $D_j, 1 \leq j \leq 10$ tais que:

\begin{itemize}
  \item $D_1, D_2, D_3 \in F_1$ documentos que abriram o Ato de Concentração.
  \item $D_4 \in F_2$ documento que foi produzido após análise da fase $F_1$.
  \item $D_5, D_6, D_7 \in F_3$ documentos que foram produzidos após a análise da fase $F_2$.
  \item $D_8 \in F_4$ documento que foi produzido após a análise da fase $F_3$.
  \item $D_9, D_{10} \in F_5$ documentos que foram produzido após a análise da fase $F_4$. Encerramento do Ato de Concentração. Como o rito já foi decidido pelo Conselho,
  não possuem valor para nós.
\end{itemize}

Conseqüentemente, temos a seguinte relação para os valores de cada um dos \textit{j} documentos considerando o \textit{pipeline} $F_i, 1 \leq i \leq 5$:
\begin{center}
  $1 = V_1 = V_2 = V_3 > V_4 > V_5 = V_6 = V_7 > V_8 > V_9 = V_{10} = 0$
\end{center}

Assim sendo, concluímos que os documentos de maior valor para nós são os mais próximos da fase inicial. Há, porém, uma pergunta que deve ser feita: por qual razão,
necessariamente, deveríamos considerar esta interpretação correta? Está questão já foi respondida: tempo. Existe ainda um outro fator que não foi mencionado aqui e será abordado
no capítulo 3 - Processamento de Linguagem Natural, seção 3.2 - Criação do Córpus, que responde a pergunta de outra maneira e portanto complementa a nossa resposta. Para adiantar a idéia, considere que os 3 tipos de
documentos presentes na fase inicial, \quotes{Notificação}, \quotes{Formulário de Notificação} e \quotes{Publicação no DOU} possuem diferentes padrões uma vez que a própria
estrutura dos documentos são diferentes. Para completar o raciocínio, lembre-se: algoritmos de aprendizado de máquina aprendem com base em padrões aprendidos no modelo
de trainamento\footnote[6]{Documentação OpenNLP: REM} (ao menos os das ferramentas usadas neste trabalho)!

Abaixo, é exposto um pouco do que cada um destes tipos de documentos contém e a diferença estrutural de cada um deles:

\begin{enumerate}[label=\textbf{\arabic*.}]
\item \textbf{Notificação}: Tem uma estrutura informativa acerca da operação, dos agentes econômicos envolvidos e dos documentos anexos a relevantes ao Ato, com pedidos
de acesso restrito para os anexos que contém informações críticas que, na opinião das empresas requerentes, caso os seus concorrentes viessem a conhecer prejudicaria o seu negócio.
\item \textbf{Formulário de Notificação}: Tem uma estrutura de perguntas e respostas, onde os agentes econômicos envolvidos respondem ao formulário do CADE. Nem todas as perguntas
são respondidas, pois mais uma vez, certas respostas as requerentes querem que se mantenham confidenciais.
\item \textbf{Publicação no DOU}: Contém poucas linhas, com informações gerais do Ato tais como as organizações envolvidas, seus advogados, número do processo, operação objeto
e setor econômico envolvido, declarando o AC público.
\end{enumerate}

\section{Ritos de um Ato de Concentração}

\indent\indent Até agora, já foi dito muito sobre o objetivo de classificar os Atos em ritos Sumário ou Ordinário, mas nada foi falado a respeito deles. Esta seção, portanto,
é dedicada a entendermos um pouco sobre eles: o que são e  qual é a sua relevância.

\indent Dizemos que um dado processo segue rito ou procedimento Sumário quando ele é simplificado de forma a ser concluído mais rápido. Tal procedimento pode ser
aplicado pelo CADE aos casos em que for considerado de pouco potencial ofensivo à concorrência as operações suficientemente simples. Nota que a decisão de enquadramento do pedido
de aprovação pelo procedimento Sumário é adotada pelo CADE em casos de conveniência e oportunidade, considerando experiências passadas adquiridas com relação a identificação
dos Atos que sejam potencialmente menos agressivos à concorrência.

Existem algumas características que tendem a ser enquadráveis em procedimento Sumário, descrita na Resolução CADE Nº 2, de 29 de maio de 2012, tais como:

\begin{enumerate}[label=\textbf{\Roman*.}]
\item \textit{Joint ventures} clássicas ou cooperativas, que visa apenas a participação em um mercado cujos produtos e serviços não
estejam horizontal ou verticalmente relacionados.
\item Substituição de agente econômico nos casos em que a empresa adquirente não participava, antes do Ato, do mercado envolvido direta ou indiretamente.
\item For provada baixa participação de mercado com sobreposição horizontal.
\item For provada baixa participação de mercado com integração vertical.
\item Ausência de nexo de causalidade, isto é, concentrações horizontais que resultem em variação de HHI inferior a 200 com uma operação que não gere controle de mais da
metade do mercado relevante.
\item Outros casos que forem considerados simples, a critério da Superintendência-Geral.
\end{enumerate}

Em teoria, todo o procedimento é considerado Ordinário até que se prove o contrário. Na prática, porém, o que se encontra é que a maior parte dos procedimentos são Sumários.

Ao submeter um Ato de Concentração a apreciação do CADE, as requerentes devem também submeter as respostas do Formulário de Notificação, que é diferente dependendo do rito.
O procedimento Ordinário possui seções 12 seções a serem respondidas, enquanto o Sumário possui apenas 7. Ainda, estas 7 seções do procedimento Sumário estão contidas no
procedimento Ordinário, mostrando que, de fato, o que difere um rito do outro é apenas a complexidade.

\pagebreak
\chapter{Processamento de Linguagem Natural (PLN)}

\indent\indent Neste capítulo falaremos um pouco sobre Processamento de Linguagem Natural (PLN), um campo da Ciência da Computação já bastante maduro que começou a ser muito
explorado a partir do ano de 1950, apesar de ainda antes desta data ser possível encontrarmos trabalhos realizados em PLN. Problemas relacionados a
Processamento de Linguagem Natural envolvem o entendimento de linguagens naturais por parte das máquinas ou mesmo geração de linguagem natural (isto é, a conversão
de uma representação entendida por computadores em uma representação em linguagem natural).

Estamos particularmente interessados na primeira
categoria de problemas de PLN mencionada, uma vez que os Atos de Concentração estão escritos em linguagem natural, mais especificamente o português, e buscamos extrair informações
deles. Isso significa, naturalmente, que é necessário que exista algum entendimento por parte da máquina sobre o conteúdo presente nos ACs, usados para construir nosso Córpus. Sendo
assim, nosso ponto de partida neste capítulo será justamente o Córpus.

\section{Córpus}

\indent\indent Já falamos muitas vezes a palavra Córpus neste trabalho, mas afinal, o que é um Córpus? Um Córpus é, como o próprio nome em latim sugere, um corpo composto de textos.
Uma coleção destes corpos é o que chamamos de \textit{Corpora}. Para trabalhar com um Córpus ou um \textit{Corpora}, é necessário que este que este seja suficientemente extenso.

Mas de quão extenso estamos falando, afinal? Um exemplo de Córpus extenso é o Brown University Standard Corpus of Present-Day American English\footnote[7]{
Versões do Brown Corpus podem ser encontradas na internet.} (ou apenas Brown Corpus), compilado na década de 1960 na universidade de Brown, Providence, Rhode Island, como um Corpus de
propósito geral no campo de linguística de corpus. Ele contém 500 exemplares de textos em inglês americano, com cerca de um milhão de palavras. Um Córpus mais modesto é o Susanne Corpus,
com aproximadamente cento e trinta mil palavras, que é na realidade um subconjunto do Brown Corpus. Mais será discutido sobre tamanho de Córpus, na seção 3.1.2 - Tamanho do Córpus,
deste mesmo capítulo.

De acordo com os autores Christopher D. Manning e Hinrich Schuetze [12], apenas para fazer a ordenação do Brown Corpus e criar uma lista de palavras nos primeiros anos de trabalho na
sua construção era necessário 17 horas dedicadas de tempo de processamento, uma vez que os computadores tinham poucos kilobytes de memória. E os problemas não terminavam por aí,
uma vez que para trabalhar com documentos deste tamanho também necessitava de discos rígidos grandes o suficiente para armazená-los. Isso significa que, apesar de PLN ser uma área
que já vem sendo explorada há algum tempo, a tecnologia poderia facilmente ser o gargalo a depender da estratégia que fosse escolhida para buscar a solução do problema. Felizmente,
com simples computadores atuais podemos realizar estas mesmas tarefas em questão de minutos.

Agora que já sabemos de que se trata um Córpus, falaremos na seção a seguir sobre o que precisamos ter em mente para criarmos um Córpus.

\subsection{Criação do Córpus}

\indent\indent Criação de um Córpus é mais complicado do que aparenta, e é um processo que apenas através da experiência empírica podemos ter uma idéia do
quão bom está Córpus que estamos montando. Existem alguns pontos de extrema relevância que devem ser considerados por alguém que está inclinado a submeter-se a esta
tarefa, destacados abaixo:

\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Linguagem}: A linguagem natural em questão. Trabalhar com textos em diferentes línguas pode não trazer bons resultados, uma vez que as línguas possuem regras
  gramaticais diferentes e diferentes formas de construção de sentenças. Frequentemente uma pessoa que está montando um Córpus irá querer submetê-lo a outros processos diversos
  tais como o de Tokenização e o de Segmentação de Setenças e estes podem se comportar diferentemente dependendo da linguagem natural em que os documentos estão escritos.
  \item \textbf{Estrutura}: A estrutura do documento, de acordo com o seu tipo, convém ser similar para todos os documentos envolvidos na montagem do Corpus. Não convém
  misturar em um mesmo Córpus, por exemplo, documentos com um formato de perguntas e respostas, tais como um formulário, com um outro documento que segue um formato dissertativo.
  A depender dos tipos de documentos que estão sendo misturados, isso pode mais atrapalhar do que ajudar na hora de buscar extrair certas informações, uma vez que os padrões
  no texto que estão sendo submetidos ao algoritmo de aprendizado podem ser muito diferentes. Pode ser que ao fazer isso, estejamos introduzindo \quotes{confusão} ao processo
  de aprendizado de máquina.
  \item \textbf{Representatividade}: Conforme mencionado por Christopher D. Manning e Hinrich Schuetze [12], os textos que formam o Córpus precisam constituir de uma amostra
  representativa da população de interesse. Em outras palavras, um determinado Córpus precisa ser fiel aos documentos reais. Para o caso deste trabalho, este item é o principal
  motivador para que construíssemos um Córpus considerando os Atos de Concentração passados na base de dados pública do CADE ao invés de usar qualquer outro Córpus de propósito
  geral para a língua portuguesa, tal como o Amazônia Corpus, disponibilizado pelo sítio da linguateca [13].
  \item \textbf{Tamanho}: O tamanho do Córpus. É de se esperar que um Córpus maior tenha mais exemplos para que o algoritmo possa gerar algum aprendizado, portanto, Córpus grandes,
  que sejam coerentes com os itens que acabamos discutir devem conseguir atingir resultados mais satisfatórios que Córpus menores.
\end{enumerate}

O Córpus desenvolvido neste trabalho foi criado a partir de cinqüenta Atos de Concentração Econômica. O critério de escolha de tais atos foi utilizar os mais recentes, assim,
todos os processos utilizados não necessariamente começaram no ano de 2016, mas estavam ou estão abertos ainda neste ano. A razão de escolher os mais recentes é para dar um pouco
mais de garantia que nosso Córpus é um pouco mais fiel à realidade, apesar dos ACs mais antigos aparentarem seguir a mesma forma de apresentação das informações.

Ainda, destes cinqüenta processos, uma metade é composta de procedimentos Sumários e a outra de procedimentos Ordinários, de tal forma que obtivessemos um Córpus resultante balanceado
com relação à representação dos ritos. Mesmo sabendo que na prática há muitos mais ritos Sumários que Ordinários, para efeitos de aprender a classificar, foi julgado mais
interessante que as amostras de cada um dos tipos aparecessem nas mesmas proporções. A seguir são listados os números dos processos utilizados:

\begin{center}
  \begin{table}
    \caption{Processos Contidos no Córpus}
    \begin{tabular}{| c | c | c | c |}
      \hline
      \multicolumn{4}{|c|}{Nº dos Processos} \\
      \hline
      \multicolumn{2}{| c }{Ordinários} & \multicolumn{2}{| c |}{Sumários} \\
      \hline
      08700.000722/2016-54 & 08700.004168/2016-84 & 08700.000625/2016-61 & 08700.005269/2016-72 \\
      08700.000723/2016-07 & 08700.004211/2016-10 & 08700.001192/2016-61 & 08700.005334/2016-60 \\
      08700.001221/2016-95 & 08700.004360/2016-71 & 08700.003684/2016-91 & 08700.005387/2016-81 \\
      08700.001872/2016-85 & 08700.004557/2016-18 & 08700.003951/2016-21 & 08700.005456/2016-56 \\
      08700.002432/2016-45 & 08700.004860/2016-11 & 08700.004768/2016-42 & 08700.005457/2016-09 \\
      08700.002792/2016-47 & 08700.005093/2016-59 & 08700.004963/2016-72 & 08700.005559/2016-16 \\
      08700.003024/2016-19 & 08700.005398/2016-61 & 08700.005000/2016-96 & 08700.005580/2016-11 \\
      08700.003045/2016-26 & 08700.005524/2016-87 & 08700.005002/2016-85 & 08700.005587/2016-33 \\
      08700.003252/2016-81 & 08700.005683/2016-81 & 08700.005138/2016-95 & 08700.005603/2016-98 \\
      08700.003421/2016-82 & 08700.005702/2016-70 & 08700.005139/2016-30 & 08700.005619/2016-09 \\
      08700.003462/2016-79 & 08700.005733/2016-21 & 08700.005204/2016-27 & 08700.005620/2016-25 \\
      08700.003636/2016-01 & 08700.010790/2015-41 & 08700.005208/2016-13 & 08700.005667/2016-99 \\
      08700.003952/2016-75 & \cellcolor{fill} & 08700.005259/2016-37 & \cellcolor{fill} \\
      \hline
      \multicolumn{4}{| c |}{Total: 50} \\
      \hline
    \end{tabular}
  \caption*{Número dos processos usados na construção do Córpus, todos do ano de 2016.}
  \end{table}
\end{center}

O Córpus resultante tem exatamente 50351 palavras\footnote[8]{Resultado obtido através do utilitário \textbf{wc}. Isso significa que, a rigor, o número de palavras
reais é um pouco menor, dado que coisas como númeração de itens são consideradas palavras.}, portanto, é um Córpus pequeno. O objetivo inicial era que o Córpus
possuisse 300 mil palavras, o que significaria utilizarmos aproximadamente 6 vezes o número de processos utilizados, ou seja, cerca de 150 processos Sumários e
150 processos Ordinários, totalizando mais ou menos 300 processos. A meta, porém, não foi atingida pelas seguintes razões:

\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Disponibilidade da Base}: Não foi um problema freqüente, mas de vez em quando a base de dados poderia estar fora do ar.
  \item \textbf{CAPTCHA}: A cada busca de documentos que é realizada na base de dados do CADE, o usuário deve submeter uma resposta a um teste CAPTCHA. Isso
  retardada o processo de obtenção de documentos consideravelmente e dificulta bastante para realizar uma tarefa de obter os documentos de forma automatizada, de tal
  forma que era mais simples fazer o processo manualmente.
  \item \textbf{Formato dos Documentos}: Todos os documentos da base de dados do CADE estão em \textit{Portable Document Format} (PDF), que é um formato agradável à
  leitura humana, mas não é dos melhores para leitura de máquina. Houve a necessidade, portanto,  de trabalharmos usando \textbf{Tesseract OCR} para fazer a conversão do
  formato PDF para textos em \textit{American Standard Code for Information Interchange} (ASCII).
  \item \textbf{Qualidade do Escaneamento}: Todos os textos presentes na base de dados são legíveis para humanos, entretanto muito deles estão com uma qualidade ruim para
  o uso do OCR. Alguns documentos tiveram de ser descartados justamente por produzirem uma resposta muito ruim após conversão.
  \item \textbf{\quotes{Sujeira} e Erros de OCR}: Mesmo os documentos que estavam com uma qualidade aceitável produziram \quotes{lixo}, que tiveram de ser descartados
  manualmente. Ainda, foram extremamente comuns erros de substituição de caracteres, em particular os latinos. Trocas de sílabas tais como "ção" e "são" muitas vezes eram
  interpretadas como "gao" ou "cao" e "6ao" e tiveram de ser corrigidas manualmente. Note que usar mecanismos de substituição automática não garantem a correção do problema,
  pois sílabas erradas em um palavra podem ser corretas em outra, portanto, ao tentarmos fazer correção automatizada, apenas transferimos muitas vezes o erro de uma palavra
  para a outra, de tal forma que é necessário passar por um processo de correção humana.
  \item \textbf{Literatura}: Ler e entender textos escritos na linguagem técnica do direito não é algo trivial uma vez que estes textos são bastante densos em informações e
  possuem um vocabulário complicado.
  \item \textbf{Exaustão}: Todos os processos manuais envolvidos unidos à dificuldade da literatura do direito legal inevitavelmente acrescentam \quotes{erros de exaustão}
  por se tratar de um processo cansativo para quem está corrigindo.
  \item \textbf{Tempo Disponível}: O prazo de 1 ano para o desenvolvimento do trabalho impede que o Córpus seja muito maior. Este Córpus de 50000 palavras tomou pouco menos de 2 meses
  para ser apenas construído e corrigido, sendo que o processo mais demorado é o de anotação, que será mencionado na próxima seção. É relevante considerar que este trabalho
  todo foi feito por apenas uma pessoa.
\end{enumerate}

Na seção a seguir falaremos sobre as anotações.

\subsection{Anotações}

\indent\indent Apesar de não constituir de uma regra, é comum que alguém que esteja trabalhando com um Córpus faça diferentes tipos de anotações sobre o mesmo.
Há diferentes tipos de anotações que podem ser feitas, tais como Tokenização, Detecção de Setenças, Etiquetas Morfológicas (\textit{Part-of-Speech Tagging}) entre outras, todas
usadas para extrair diferentes tipos de informações dos textos. Em particular, mais será abordado sobre as duas primeiras nas próximas seções.

Anotações, portanto, constituem de metadados sobre os dados. Comumente, linguagens como \textit{Standard Generalized Markup Language} (SGML) ou
\textit{eXtensible Markup Language} (XML) são utilizadas para fazer marcações sobre texto, mas
neste trabalho, as anotações foram feitas utilizando uma ferramenta relativamente nova chamada BRAT, que possui um
formato próprio e que o OpenNLP, uma ferramenta celebrada na área de Processamento de Linguagem Natural, reconhece o formato.
Mais será falado sobre estas ferramentas no capítulo 5 - Ferramentas Utilizadas.

\section{Tokenização}

\indent\indent Tokenização é freqüentemente um dos primeiros processos envolvidos no processamento de textos escritos em linguagens naturais. Uma \textit{Token} nada mais é que uma
palavra, um número ou mesmo pontuações (só que o tratamento de pontuações, especificamente, pode variar de acordo com o texto em questão)[12]. Naturalmente, surge a necessidade de
definir, portanto, o que é uma palavra.

Conforme sugerido em (Kučera e Francis, 1967), uma palavra, para efeitos computacionais, é uma \textit{string} com caracteres alfanuméricos
contíguos, delimitada por espaços em branco e que pode conter hífens e apóstrofos e mais nenhuma outra forma de pontuação. Tal definição é demasiadamente simplista,
mas pode funcionar a depender do tipo de texto que está sendo usado. Uma outra aproximação ainda menos sofisticada é a estratégia do utilitário \textbf{wc}, já mencionado
aqui na nota de rodapé número 8, que simplesmente considera caracteres contíguos delimitados por espaços em branco como uma palavra, independente da sua natureza. Assim, por exemplo,
a \textit{string} de dois caracteres C\# será considerada uma palavra de acordo com a segunda definição, mas não com a primeira.

Fica claro, portanto, que a definição de palavra a ser usada é fundamental para efeitos de marcação e que esta vai afetar diretamente os resultados obtidos, de tal forma que as
respostas conseguidas com um Córpus que considera palavras com uma definição A gerará saídas diferentes do mesmo Córpus considerando palavras com uma definição B.

\subsection{Tokenização nas Notificações dos Atos de Concentração}

\indent\indent Existem outros problemas que surgem no processo de Tokenização além do que será considerado uma palavra. Um leitor observador pode ter percebido que ambos os exemplos anteriormente
mancionados colocam grande importância nos espaços em branco para delimitar uma palavra, porém existem linguagens naturais que não fazem uso do espaço em branco entre palavras, e
estes problemas também são pertinentes ao processo de Tokenização. Ainda, palavras não aparecem sempre delimitadas entre espaços em branco em um texto. Considere o seguinte trecho,
retirado da Notificação do Ato de Concentração nº 08700.004168/2016-84:

\begin{quote}
  \textit{\quotes{16. Conforme exigido no art. 110, §3 da Resolução CADE nº 1/2012, as Requerentes declaram que (i) todas as informações apresentadas são, ao que é de seu
  conhecimento, verdadeiras e corretas; (ii) todos os documentos e cópias de documentos anexos à presente notificação são autênticos ou cópias fiéis de suas versões originais;
  e (iii) todas as estimativas foram feitas de boa-fé, de acordo com as melhores informações disponíveis.}}
\end{quote}

Vejamos o que acontece com o seguinte trecho considerando as duas aproximações mencionadas anteriormente destacando os problemas encontrados em ambas em \hl{amarelo}.

\textbf{I.} Aproximação de (Kučera e Francis, 1967): caracteres alfanuméricos contíguos, com hífens e apostrofos, delimitados por espaços em branco constituem uma palavra.

\begin{quote}
  \textit{\quotes{\hl{16}. Conforme exigido no \hl{art}. \hl{110}, §\hl{\mbox{3}} da Resolução CADE \hl{n}º \hl{1/2012}, as Requerentes declaram que \hl{(i)} todas as informações apresentadas \hl{\mbox{são}}, ao que é de seu
  \hl{conhecimento}, verdadeiras e \hl{corretas}; \hl{(ii)} todos os documentos e cópias de documentos anexos à presente notificação são autênticos ou cópias fiéis de suas versões \hl{originais};
  e \hl{(iii)} todas as estimativas foram feitas de \hl{\mbox{boa-fé}}, de acordo com as melhores informações \hl{\mbox{disponíveis}}.}}
\end{quote}

Com relação a esta aproximação notavelmente há problemas relacionados a \textit{períodos}. Pontuações como vírgula, ponto-e-vírgula e ponto final acabam freqüentemente sendo um dos
delimitadores de algumas palavra ao invés de um espaço em branco. Há também pontos em abreviações, como no caso de \quotes{art.}, e o caracter \quotes{/} que faz parte do número da
Resolução do CADE mencionada no trecho. Notemos ainda que o trecho é o décimo sexto item de alguma seção do documento, então o ponto que sucede o 16 configura outro tipo de problema,
aqui também relacionado ao delimitador ser diferente de um espaço em branco. As listagens dos itens em algarismos romanos entre parenteses e o caracter especial § que antecede o número
do artigo também são problemáticos no que diz respeito a esta aproximação. Em todos estes casos, estas palavras \textit{não serão consideradas palavras} pelo processo de tokenização.

\textbf{II.} Aproximação do utilitário \textbf{wc}: caracteres contíguos, delimitados entre espaços.

\begin{quote}
  \textit{\quotes{16. Conforme exigido no art. \hl{110,} §3 da Resolução CADE nº \hl{1/2012,} as Requerentes declaram que (i) todas as informações apresentadas \hl{\mbox{são,}} ao que é de seu
  \hl{conhecimento,} verdadeiras e \hl{corretas;} (ii) todos os documentos e cópias de documentos anexos à presente notificação são autênticos ou cópias fiéis de suas versões \hl{originais;}
  e (iii) todas as estimativas foram feitas de \hl{\mbox{boa-fé,}} de acordo com as melhores informações \hl{\mbox{disponíveis.}}}}
\end{quote}

Curiosamente, um problema contrário ocorre com a segunda definição. Aqui, conforme pode ser visto acima, as pontuações de período \textit{são consideradas parte das palavras}, algo
indesejado a depender do tipo da aplicação.

Desta forma, fica claro que a depender do resultado que se está procurando, uma tokenização pode obter resultados melhores ou piores que outra. Para efeitos deste trabalho,
vale recordar de que como estamos lidando com tecnologia de OCR, parece ser mais vantajoso considerar a aproximação do utilitário \textbf{wc} sobre a dos autores
Francis e Kučera, de tal modo que assim diminuímos os riscos de descartar palavras relevantes em determinados contextos.

Ainda, além da questão do OCR, sabemos que os Atos de Concentração são constituídos de documentos oficiais de grandes organizações, ora submetidos à apreciação das
autoridades legais do CADE, e portanto não devem apresentar cadeias de caracteres contíguas inesperadas, fora do português (com um ou outro estrangeirismos
potencialmente oriundos do inglês).

Por fim, não é um problema que a pontuação do período seja incluída nas \textit{tokens} para nós, uma vez que ela não é capaz de eliminar sozinha o sentido do contexto da qual
a \textit{token} foi retirada. O modelo de tokenização usado no trabalho é fornecido na página do OpenNLP para a língua portuguesa. Apesar de não ser o ideal, ele se comporta
dentro do esperado. Idealmente, deve-se considerar criar um Córpus composto de Atos de Concentração para treinar a tokenização e gerar um modelo com melhor representatividade.

\section{Detecção de Setenças}

\indent\indent Outro processo que freqüentemente aparece nas primeiras etapas junto à tokenização é o de detecção de sentenças. Este processo consiste em
quebrar um texto em sentenças e é importante por uma série de razões, como o uso posterior de \textit{POS Tagging} e, no nosso caso, Reconhecimento de Entidades Mencionadas, uma
vez que estes processos posteriores precisam saber onde começam e terminam uma sentença para buscar as palavras que devem ser etiquetadas. Outros nomes que o processo de
detecção de sentenças possui são Quebra de Sentenças (\textit{Sentence Breaking}) e Desambiguação de Fronteira de Sentença (\textit{Sentence Boundary Disambiguation - SBD}).

Semelhantemente ao processo de tokenização, que surgia a necessidade de saber o que é uma palavra, aqui precisamos saber, então, o que é uma sentença. Uma das aproximações
mais comuns é identificar os períodos, pois 90\% deles são indicadores de limites de sentenças (Riley 1989), conforme descrevem Manning e Schuetze [12] em seu livro.

Já havíamos chamado atenção aos períodos na seção anterior, quando falamos de tokenização, e agora em Detecção de Sentenças eles ressurgem com uma importância ainda maior. Finais de
períodos são freqüentemente marcados por pontuações tais como os pontos final, de interrogação, de exclamação dentre outros, mas nem toda linguagem natural faz uso
de pontuações, como por exemplo o tailandês.

Os autores Manning e Schuetze [12] em seu livro mencionam também pesquisas diversas em detecção de sentenças que foram realizadas ao longo das últimas décadas e o quanto
os resultados melhoraram no decorrer deste tempo, de tal forma que hoje em dia já são conhecidas técnicas para predição de identificação das fronteiras de sentenças com uma
taxa de precisão superior a 99\%.

Conforme pode ser observado com o aqui exposto e de acordo com (Indurkhya e Damerau, 2010) [15], o escopo do problema de detecção de setenças varia de acordo com o idioma
a ser trabalhado. Além disso, os autores também consideram a importancia do contexto: supondo que tenhamos diferentes \textit{corpora}, a maneira como os documentos que os
constituem são redigidos variam de um meio pro outro, por exemplo, um \textit{corpora} formado apenas de textos jornalísticos pode ter sentenças com padrões diferentes de um outro
\textit{corpora} formado apenas pelas obras de autoria de William Shakespeare.

\subsection{Detecção de Sentenças nas Notificações dos Atos de Concentração}

\indent\indent Apesar das Notificações dos ACs seguirem um padrão, tais documentos são redigidos por pessoas diferentes, representando diferentes organizações, e inevitavelmente
podem acabar tendo estilos de escrita um tanto diferentes uns dos outros. Estes estilos podem acabar sendo refletidos diretamente no uso das pontuações, e conseqüentemente,
na identificação das fronteiras de um período, causando flutuações pequenas.

Um problema que surge, em particular, é o de que a depender do tipo de literatura em questão, os períodos tendem a ter um número médio de palavras, enquanto que
nos Atos, certos períodos podem ser demasiadamente compridos, fugindo um pouco das regras e dificultando para o modelo de quebra de sentenças.
Por exemplo: todos os Atos de Concentração se iniciam com um pequeno resumo apresentando as organizações envolvidas, o pedido formal de submissão do AC à apreciação do CADE
com referências às Leis e contratos pertinentes à ação, e vez ou outra também o pedido do tipo de rito sumário ou ordinário e a operação que anseiam realizar.

Este pequeno resumo, para efeitos de REM, é especialmente complicado de quebrar em sentenças, uma vez que sempre aparecem entidades mencionadas
em uma posição de texto que estão relacionadas a outras há muitos caracteres (ou mesmo palavras) de distância. Notemos ainda que estes trechos não possuem pontuações como pontos finais ou
exclamações, de tal forma que o pequeno resumo deve ser considerado inteiro a própria sentença.

Um exemplo destes resumos presentes nas Notificações dos ACs é reproduzido a seguir, retirado do Ato de Contração nº 08700.005683/2016-81:

\begin{quote}
  \textit{\quotes{UNIPAR CARBOCLORO S.A. (“Unipar Carbocloro”), sociedade anônima de capital aberto devidamente constituída de acordo com a legislação brasileira, com sede na Rua
  Joaquim Floriano, nº 960, 15º andar, Itaim Bibi, CEP 04534—004, na cidade de São Paulo, no Estado de São Paulo, no Brasil, SOLVAY INDUPA S.A.I.C. (“Solvay Indupa”),
  sociedade anônima de capital aberto devidamente constituída de acordo com a legislação argentina, com sede na Avenida Alicia Moreau de Justo, 1930, 4º andar, na cidade de
  Buenos Aires, na Argentina, e SOLVAY INDUPA DO BRASIL S.A. (“Indupa Brasil” e, em conjunto com a Unipar Carbocloro e com a Solvay Indupa, “Requerentes”), sociedade anônima
  de capital fechado devidamente constituída de acordo com a legislação brasileira, com sede na Rua Urussui, 300, 3º andar, Itaim Bibi, CEP 04542-903, na cidade de São Paulo,
  no Estado de São Paulo, no Brasil, vêm, respeitosamente, por seus advogados, submeter à apreciação do Conselho Administrativo de Defesa Econômica (“CADE”), em observância aos
  artigos 53, 88 e 90 da Lei 12.529, de 30 de novembro de 2011, a aquisição do controle societário da Solvay Indupa pela Unipar Carbocloro.}}
\end{quote}

Conforme podemos ver no exemplo acima, de fato, a única pontuação que pode ser considerada tradicionalmente como o final de uma sentença só ocorre com o término do trecho. Este trecho
sozinho tem exatamente \textit{181 palavras}, considerando a aproximação do \textbf{wc}, que é um número \textbf{muito distante} do que um \quotes{período normal} contém. A média
de caracteres considerando os resumos de todos os processos que constituem o nosso Córpus, listados na tabela 3.1, é de \textit{140.72 palavras por resumo}.

Uma observação final: apesar do exemplo acima conter quase 40 palavras a mais que a média calculada, este não é o resumo que contém mais palavras.

É importante ressaltar aqui que, assim como no processo de tokenização, foi usado o modelo de detecção de setenças fornecido na própria página do OpenNLP, uma vez que o tempo era
apertado para desenvolver um Córpus para servir de treinamento para quebra de setenças. Os resultados, apesar de serem satisfatórios, poderiam ser refinados com um modelo
de detecção de setenças criado a partir de Atos de Concentração, uma vez que, assim como na tokenização, aumentaríamos a representatividade do Córpus com relação aos documentos
reais.

No próximo capítulo discutiremos sobre REM e como foram feitas as marcações no Córpus. Até então, tudo o que foi discutido no capítulo 2 - O Conselho Administrativo de Defesa Econômica (CADE) e neste capítulo 3 - Processamento de Linguagem Natural eram
requisitos para poder trabalhar com REM nos Atos de Concentração, e uma vez entendidos, será mais simples para o leitor entender a forma que o Reconhecimento de Entidades
Mencionadas foi usado para chegarmos nos resultados e conclusões escritos nos dois capítulos finais desta monografia.

\pagebreak
\chapter{Reconhecimento de Entidades Mencionadas (REM)}

\indent\indent Neste capítulo falaremos um pouco sobre Reconhecimento de Entidades Mencionadas (REM), uma subtarefa da área de Extração de Informações que busca localizar e classificar
palavras de um texto escrito em alguma linguagem natural em entidades previamente definidas tais como nomes de pessoas e nomes de organizações. Também mostraremos como
aplicamos o Reconhecimento de Entidades Mencionadas para os Atos de Concetração Econômica que são apreciados pelo Conselho Administrativo de Defesa Econômica.

\section{Entidades Mencionadas}

\indent\indent Não faz sentido falarmos sobre Reconhecimento de Entidades Mencionadas sem saber, de certo, o que é uma entidade mencionada (ou entidade nomeada), portanto este
será o nosso ponto de partida neste capítulo. Afinal, do que se trata uma entidade mencionada?

Uma entidade mencionada é um objeto que existe no mundo real e que possui um nome próprio, como por exemplo, uma pessoa ou uma organização, tal como já foi mencionado na introdução
deste capítulo. Note, porém, que pessoas e organizações possuem naturezes existenciais diferentes, no sentido de que uma pessoa pode ser encarada como um objeto \textit{físico} do mundo real
ao passo que uma organização pode ser encarada como um objeto \textit{abstrato}. Independente disso, porém, ambas possuem seus \textit{tipos de entidade} muito bem definidos
(pessoa e organização) e para efeitos de entidades mencionadas, não é relevante que determinado objeto seja necessariamente real ou virtual.

É relevante ressaltar que entidades mencionadas são temporais no sentido de que certos tipos de entidades podem assumir um sentido em um contexto e outro em um segundo contexto.
Sabendo que entidades mencionadas contém tanto expressões com nomes quanto com números, uma entidade relacionada a valor monetário pode ter um sentido em um determinado
contexto histórico e outro em um contexto futuro ou passado.

\section{Reconhecimento e Classificação}

\indent\indent O processo de Reconhecimento de Entidades Mencionadas resume-se a basicamente duas subtarefas: reconhecimento (ou identificação) e classificação (ou etiquetagem)
de entidades, nesta ordem. Primeiro, aprende-se sobre o modelo de REM gerado a partir do Córpus anotado, e na seqüência, busca-se reconhecer, dentre todas as \textit{tokens}
que compõem o Córpus, aquelas que são possíveis entidades. Uma vez com estas \textit{tokens} selecionadas, para cada uma delas, dentre todas as possíveis classificações
previamente estabelecidas, seleciona-se a classificação a mais provável para determinada \textit{token}.

Aqui o leitor já deve perceber mais claramente por quais razões é necessário passar pelos processos de tokenização e detecção de sentenças. As entidades são, necessariamente,
compostas por ao menos uma \textit{token} e ocorrem em períodos bem determinados, de tal forma que as entidades em um mesmo período podem se relacionar de alguma forma. Assim,
ao quebrarmos o Córpus em \textit{tokens} e sentenças, a aplicação passa a conhecer quem são todas as candidatas a entidades mencionadas e em que contexto elas ocorrem.

\subsection{Reconhecimento de Entidades Mencionadas nas Notificações dos Atos de Concentração}

\indent\indent Já falamos nas seções anteriores sobre os processos de tokenização e detecção de sentenças dos Atos de Concentração. Nesta seção, a partir de um exemplo simples e
de maneira superficial, apresentamos como acontece o processo de Reconhecimento de Entidades Mencionadas nos ACs, desde a a tokenização até o final. Não serão explorados aqui
o que está por trás disso, uma vez que isso depende da implementação do algoritmo da ferramenta e não é relevante para esta seção.

Suponhamos, primeiramente, que temos definidos os seguintes tipos de entidade em um documento de texto:

\begin{itemize}
  \item Document
  \item Organization
\end{itemize}

Consideremos o trecho a seguir, retirado do Ato de Concentração nº 08700.005269/2016-72, o qual queremos marcar de forma automatizada as \textit{tokens} relativas
aos dois tipos de entidade definidas acima:

\begin{quote}
  \textit{\quotes{2. A OP atualmente detém 20\% de participação no Contrato de Concessão, enquanto a QGOG detém outros 20\%.
  A Petrobras detém os 60\% de participação remanescente no Contrato de Concessão; a Petrobras também é a operadora designada
  pela Cláusula 4.1 do Joint Operating Agreement ("JOA").}}
\end{quote}

Ao aplicarmos o processo de tokenização, considerando que tenhamos à disposição um bom modelo gerado a partir do treinamento de um Córpus devidamente anotado para esta tarefa,
esperamos como resposta algo como o exposto abaixo, onde cada \textit{token} encontrada está contida em um \textit{frame}:

\begin{quote}
  \fbox{2.} \fbox{A} \fbox{OP} \fbox{atualmente} \fbox{detém} \fbox{20\%} \fbox{de} \fbox{participação} \fbox{no} \fbox{Contrato} \fbox{de} \fbox{Concessão,}
  \fbox{enquanto} \fbox{a} \fbox{QGOG} \fbox{detém} \fbox{outros} \fbox{20\%.}
  \fbox{A} \fbox{Petrobras} \fbox{detém} \fbox{os} \fbox{60\%} \fbox{de} \fbox{participação} \fbox{remanescente} \fbox{no} \fbox{Contrato} \fbox{de} \fbox{Concessão;} \fbox{a}
  \fbox{Petrobras} \fbox{também} \fbox{é} \fbox{a} \fbox{operadora} \fbox{designada}
  \fbox{pela} \fbox{Cláusula} \fbox{4.1} \fbox{do} \fbox{Joint} \fbox{Operating} \fbox{Agreement} \fbox{("JOA").}
\end{quote}

No exemplo de saída imediatamente acima, aceitamos para efeitos de simplificação, que a pontuação faz parte da \textit{token} que a procede.
Geralmente a pontuação sozinha é encarada como uma \textit{token}.

O próximo passo é aplicarmos o processo de detecção de sentenças. Assim como no processo de tokenização, consideraremos que tenhamos à disposição um bom modelo
gerado a partir do treinamento de um Córpus devidamente anotado para esta tarefa. A saída esperada é mostrada a seguir, onde cada uma das sentenças identificadas está contida
em um \textit{frame} diferente:

\begin{quote}
  \fbox{
      \begin{varwidth}{0.86\textwidth}
      2. A OP atualmente detém 20\% de participação no Contrato de Concessão, enquanto a QGOG detém outros 20\%.
      \end{varwidth}}
\end{quote}

\begin{quote}
  \fbox{
      \begin{varwidth}{0.86\textwidth}
      A Petrobras detém os 60\% de participação remanescente no Contrato de Concessão;
      \end{varwidth}}
\end{quote}

\begin{quote}
  \fbox{
      \begin{varwidth}{0.86\textwidth}
      a Petrobras também é a operadora designada pela Cláusula 4.1 do Joint Operating Agreement ("JOA").
      \end{varwidth}}
\end{quote}

Uma vez realizados os dois processos anteriores e a partir dos seus resultados, poderíamos então obter do processo de Reconhecimento de Entidades Mencionadas,
finalmente, a seguinte resposta, onde cada entidade mencionada está contida em um \textit{frame} e sua classificação final apresenta-se subescrita no canto inferior direito deste:

\begin{quote}
  \begin{varwidth}{0.95\textwidth}
  2. A \fbox{OP}$_{\text{Organization}}$ atualmente detém 20\% de participação no \fbox{Contrato de Concessão,}$_{\text{Document}}$ enquanto a \fbox{QGOG}$_{\text{Organization}}$
  detém outros 20\%. A \fbox{Petrobras}$_{\text{Organization}}$ detém os 60\% de participação remanescente no \fbox{Contrato de Concessão;}$_{\text{Document}}$ a
  \fbox{Petrobras}$_{\text{Organization}}$ também é a operadora designada pela Cláusula 4.1 do \fbox{Joint Operating Agreement ("JOA").}$_{\text{Document}}$
  \end{varwidth}
\end{quote}

Todo este processo é muito bonito, mas a realidade é que nem sempre os documentos se comportam bem assim. Recordemos que o processo de Reconhecimento das Entidades Mencionadas
é divido em duas etapas: identificação e classificação. Pois bem, o que acontece na realidade é que ambas as etapas podem ter erros que devem ser medidos. Com relação
à atividade de identificação, é comum que a aplicação falhe ao identificar algumas \textit{tokens} que deveriam ser marcadas, passando por elas despercebidamente. Naturalmente, isso
implica na não classificação da entidade relativa a esta \textit{token} que aconteceria na etapa seguinte. Já na etapa de classificação, o que pode acontecer são erros de etiquetagem
de duas naturezas diferentes: precisão das fronteiras e decisão da etiqueta. Exploraremos mais sobre estes erros e como medir a precisão, a cobertura e a medida-F na próxima seção.

\section{Avaliação das Informações Extraídas}

\indent\indent Ao trabalharmos com algoritmos que realizam a atividade de marcação de textos de forma automatizada com base em um Córpus que desenvolvemos, é
esperado que busquemos métodos e técnicas para medir quão corretas estas anotações geradas estão. A obtenção destes valores é particularmente
importante no que diz respeito à própria continuidade do desenvolvimento do Córpus, de tal forma que podemos usá-los para nossa orientação e
reconhecermos a partir disso se o nosso critério de marcação está sendo mais ou menos efetivo em relação à resposta esperada.

Esta seção, portanto,
é reservada para que exploremos métodos e conceitos relacionados à avaliação.

\subsection{Padrão-ouro}

\indent\indent Uma das formas de avaliação mais utilizadas de um sistema de Reconhecimento de Entidades Mencionadas é a comparação da saída obtida com a do texto anotado por
um especialista, também conhecido como \textit{padrão-ouro} (ou \textit{gold-standard}, em inglês). Apesar desta idéia ser intuitiva e fácil de aceitar, a realidade é que
comumente o tipo de texto que uma pessoa pretende estudar não tem um Córpus padrão-ouro disponível, que é justamente e não surpreendentemente o caso deste trabalho. Isto ocorre
por uma série de motivos tais como o tempo e o custo, uma vez que desenvolver um bom Córpus é um processo que consome bastante tempo, bem como o tempo de trabalho de um \textit{expert}
pode ter um custo elevado.

Assim sendo, as anotações manuais realizadas sobre os Atos de Concentração foram consideradas o padrão-ouro do trabalho desenvolvido. Idealmente,
deveríamos ter um Córpus anotado para ser o padrão-ouro e outro que serviria de treinamento, porém, como não há tempo de desenvolver tantos Corpora diferentes, tivemos de nos
contentar usando o próprio modelo de treinamento como padrão-ouro. Portanto, sempre que o termo \quotes{padrão-ouro} for usado nesta literatura, estaremos nos referindo ao Córpus
anotado composto pelos cinqüenta ACs listados na tabela 3.1.

\subsection{Tipos de Erro}

\indent\indent Uma vez com um Córpus construído e um padrão-ouro a ser tomado de referência, podemos facilmente identificar os erros que surgem na saída obtida. O autor
Wesley Seidel de Carvalho [16], em sua tese de mestrado para a Universidade de São Paulo, apresenta 5 tipos de erro diferentes ao leitor a partir de um exemplo, listados a seguir:

\begin{enumerate}[label=\textbf{E\arabic*.}]
  \item Marcação de entidade inexistente: o máquina marcou uma ou mais \textit{tokens} que não deveriam ter sido marcadas.
  \item Marcação perdida: a máquina passou despercebidadamente por uma ou mais \textit{tokens} contíguas que deveriam ter sido marcadas.
  \item Tipo da etiqueta: a máquina identificou corretamente uma entidade, mas errou na sua classificação.
  \item Fronteira da etiqueta: a máquina identificou corretamente uma entidade, mas incluiu ou perdeu \textit{tokens} que não deveria.
  \item Tipo e fronteira da etiqueta: a máquina identificou corretamente uma entidade, mas incluiu ou perdeu \textit{tokens} que não deveria e atribuiu à entidade uma etiqueta errada.
\end{enumerate}

Uma pessoa poderia sugerir mais ou menos tipos de erros além
dos listados acima, mas o fato é que para qualquer sistema de REM estamos interessados em pelo menos duas categorias de erro: aqueles que estão relacionados à etapa de identificação
e aqueles que estão relacionados à etapa de classificação.

Na listagem acima, podemos perceber facilmente que os erros \textbf{E1} e \textbf{E2} estão relacionados à etapa de identificação do procedimento de REM, enquanto que
os erros \textbf{E3}, \textbf{E4} e \textbf{E5} estão relacionados à etapa de classificação. Assim, uma pessoa poderia facilmente definir apenas dois erros ao invés
de cinco se bem entendesse, mas estaria perdendo detalhamento da informação acerca dos erros obtidos ao fazê-lo.

Para ilustrar o que acabamos de dizer, suponhamos primeiramente que temos as seguintes entidades mencionadas definidas em um documento de texto:

\begin{itemize}
  \item Document
  \item Operation
  \item Organization
\end{itemize}

E consideremos o trecho a seguir, retirado do Ato de Concentração nº 08700.005524/2016-87, do qual queremos extrair informações a partir da entidades mencionadas
declaradas:

\begin{quote}
  \textit{\quotes{Por meio da presente operação, a HNA visa a obter benefícios econômicos decorrentes dos novos investimentos para expansão dos negócios da gategroup,
  bem como a  estabilidade e  continuidade do plano estratégico denominado Gateway 2020, lançado pela gategroup em 2015, com foco em inovação, expansão geográfica e eficiência.}}
\end{quote}

\pagebreak Cujo padrão-ouro é definido a seguir:

\begin{quote}
  \begin{varwidth}{0.89\textwidth}
  Por meio da \fbox{presente operação}$_{\text{Operation}}$, a \fbox{HNA}$_{\text{Organization}}$ visa obter benefícios econômicos decorrentes dos novos investimentos para
  expansão dos negócios da \fbox{gategroup}$_{\text{Organization}}$, bem como a
  estabilidade e  continuidade do plano estratégico denominado \fbox{Gateway 2020}$_{\text{Document}}$, lançado pela \fbox{gategroup}$_{\text{Organization}}$ em 2015,
  com foco em inovação, expansão geográfica e eficiência.
  \end{varwidth}
\end{quote}

E finalmente, consideremos também os erros seguintes:

\begin{enumerate}[label=\textbf{e\arabic*.}]
  \item Marcação perdida: a máquina passou despercebidadamente por uma ou mais \textit{tokens} contíguas que deveriam ter sido marcadas (\textbf{E2}).
  \item Atribuição de etiqueta: a máquina errou na classificação, de tal forma que ou atribuiu uma etiqueta errada  para uma ou mais \textit{tokens}
  contíguas que \textit{representam} uma entidade ou atribuiu qualquer etiqueta para uma ou mais \textit{tokens} contíguas que \textit{não representam} uma entidade
  (\textbf{E1} + \textbf{E3} + \textbf{E5}).
  \item Fronteira da etiqueta: a máquina identificou corretamente uma entidade, mas incluiu ou perdeu \textit{tokens} que não deveria (\textbf{E4}).
\end{enumerate}

Agora, suponhamos que a saída que obtivemos foi:

\begin{quote}
  \begin{varwidth}{0.89\textwidth}
  Por meio da presente \fbox{operação}$_{\text{Operation}}$, a \fbox{HNA}$_{\text{Organization}}$ visa obter benefícios econômicos decorrentes dos novos investimentos
  para expansão dos negócios da gategroup,
  bem como a  estabilidade e  continuidade do \fbox{plano estratégico}$_{\text{Document}}$ denominado \fbox{Gateway 2020}$_{\text{Organization}}$, lançado pela gategroup
  em 2015, com foco em inovação, expansão geográfica e eficiência.
  \end{varwidth}
\end{quote}

Podemos, então, construir a seguinte tabela a partir dos resultados obtidos, denotando os acertos por \textbf{A}:


\begin{table}[h!]
  \centering
  \def\arraystretch{2}
  \begin{tabular}{| c | c | c | c | c |}
    \hline
    \multicolumn{5}{|c|}{Exemplo} \\
    \hline
    Resultado Esperado & Resultado Obtido & Ocorrências & Avaliação 1 & Avaliação 2 \\
    \hline\hline
    \fbox{presente operação}$_{\text{Operation}}$ & \fbox{operação}$_{\text{Operation}}$         & 1 & \textbf{E4} & \textbf{e3} \\ \hline
    \fbox{HNA}$_{\text{Organization}}$            & \fbox{HNA}$_{\text{Organization}}$           & 1 & \textbf{A}  & \textbf{A}  \\ \hline
    \fbox{gategroup}$_{\text{Organization}}$      & gategroup                                    & 2 & \textbf{E2} & \textbf{e1} \\ \hline
    plano estratégico                             & \fbox{plano estratégico}$_{\text{Document}}$ & 1 & \textbf{E1} & \textbf{e2} \\ \hline
    \fbox{Gateway 2020}$_{\text{Document}}$       & \fbox{Gateway 2020}$_{\text{Organization}}$  & 1 & \textbf{E3} & \textbf{e2} \\ \hline \hline
    \multicolumn{5}{| c |}{Total: 1 Acerto e 5 Erros para cada uma das avaliações} \\ \hline
  \end{tabular}
\end{table}

Em suma, as classificações dos tipos de erros que
serão considerados dependem bastante do que o pesquisador julgar relevante. Note que a quantidade de erros encontrada no final será a mesma em ambos os casos,
diferindo apenas no número de categorias em que estes erros todos serão distribuídos.

Além dos erros, é claro, também estamos interessados na quantidade de acertos. Uma vez em posse dos valores que definem as quantidades de erros e acertos em relação
ao padrão-ouro podemos, finalmente, utilizarmos de métricas para analisarmos o rendimento do nosso Corpus. Exploraremos algumas destas métricas na seção seguinte.

\subsection{Métricas de Avaliação}

\indent\indent Métricas têm uma importância fundamental para qualquer trabalho sério, uma vez que elas conferem maior credibilidade aos resultados caso elas façam
sentido em determinado contexto. Elas servem para aumentar a garantia da qualidade do produto final (que pode ser a saída de um \textit{software}), bem como podem
ser encaradas como um valor que indique quão bem o desenvolvimento do trabalho está caminhando em determinado ponto.

Algumas métricas foram propostas para que fosse analisado o rendimento de sistemas de RI. Nesta seção, falaremos sobre as métricas tradicionalmente mais utilizadas quando trabalhamos
com Reconhecimento de Entidades Mencionadas: a precisão, a cobertura e a medida-F. Estas métricas podem ser facilmente encontradas em diversas literaturas de
Recuperação de Informações tais como a dos autores Manning, Raghavan e Schuetze [20], bem como na própria dissertação de mestrado do Wesley Seidel de Carvalho [16], já mencionada na seção anterior, em que abordamos o assuntos dos tipos de erros.

Antes de falarmos das métricas especificamente, porém, é relevante considerarmos que uma determinada informação pode ter uma das quatro categorias distintas a seguir:

\begin{itemize}
 \item \textbf{Verdadeiros Positivos} (\textbf{VP}): EMs relevantes e recuperadas.
 \item \textbf{Falsos Positivos} (\textbf{FP}): EMs não relevantes e recuperadas.
 \item \textbf{Falsos Negativos} (\textbf{FN}): EMs relevantes e não recuperadas.
 \item \textbf{Verdadeiros Negativos} (\textbf{VN}): EMs não relevantes e não recuperadas.
\end{itemize}

Uma vez definidas estas quatro categorias, podemos agora prosseguir para as métricas.

\subsubsection{Precisão}

\indent\indent A precisão (\textbf{P}) é definida como a razão entre o número de itens relevantes recuperados e o número de itens recuperados.
Em outras palavras, é a taxa de itens recuperados corretamente dentre todos os que foram recuperados. Matematicamente, a definimos como

\begin{equation}
 \text{\textbf{P}} = \dfrac{\text{\#itens relevantes recuperados}}{\text{\#itens recuperados}}
\end{equation}

Deste modo, a fórmula (4.1) acima pode ser reescrita como

\begin{equation}
 \text{\textbf{P}} = \dfrac{\text{\textbf{VP}}}{\text{\textbf{VP}} + \text{\textbf{FP}}}
\end{equation}

Note que essa métrica diz bastante
a respeito dos erros da etapa de classificação, mas não traz informações acerca da etapa de identificação, uma vez que ela desconsidera os erros de
marcações perdidas mencionados na seção anterior. Seu objetivo é nos mostrar o quão \textit{precisa} está a nossa coleta. Isso faz com que surja naturalmente a necessidade de uma segunda métrica que considere a recuperação em relação a coleção: a cobertura (\textbf{C}).

\subsubsection{Cobertura}

\indent\indent A cobertura (\textbf{C}) é definida como a razão entre o número de itens relevantes recuperados e o número de itens relevantes.
Em outras palavras, é a taxa de itens recuperados corretamente dentre todos os que deveriam ter sido recuperados na coleção. Matematicamente, a definimos como

\begin{equation}
 \text{\textbf{C}} = \dfrac{\text{\#itens relevantes recuperados}}{\text{\#itens relevantes}}
\end{equation}

Assim, a fórmula (4.3) acima pode ser reescrita como

\begin{equation}
 \text{\textbf{C}} = \dfrac{\text{\textbf{VP}}}{\text{\textbf{VP}} + \text{\textbf{FN}}}
\end{equation}

Ao contrário da precisão (\textbf{P}), agora nós não temos mais uma idéia do quanto a nossa coleta está precisa, mas sim o quanto ela \textit{cobriu} das marcações esperadas. Este é um modo de enfatizar todas as entidades que deveriam ser identificadas num cenário ideal, portanto, dando maior foco na etapa de identificação do processo de REM.

\subsubsection{Medida-F}

\indent\indent Seria interessante podermos juntar tanto a precisão (\textbf{P}) quanto a cobertura (\textbf{C}) em uma única métrica. Para isso, foi definida a medida-F (\textbf{F}), descrita
pela seguinte equação:

\begin{equation}
 \text{\textbf{F}} = \dfrac{1}{\alpha\dfrac{1}{\text{\textbf{P}}} + (1 - \alpha)\dfrac{1}{\text{\textbf{C}}}} = \dfrac{(\beta^2 + 1)\text{\textbf{PC}}}{\beta^2\text{\textbf{P}} + \text{\textbf{C}}}
\end{equation}

onde a relação entre os coeficientes $\alpha$ e $\beta$ é dada por

\begin{equation}
 \beta^2 = \dfrac{1 - \alpha}{\alpha} \enspace\enspace\enspace\enspace\enspace \alpha \in [0, 1]\text{,\enspace}\beta^2 \in [0, \infty]
\end{equation}

O objetivo da medida-F não é apenas uni-las em uma métrica, mas também podemos aumentar a enfase na cobertura a custo de precisão e vice-versa, uma vez que se trata de uma média harmônica ponderada.

Para usarmos a equação da medida-F na sua \textit{forma balanceada}, isto é, com pesos iguais para ambas a precisão e a cobertura, basta atribuirmos ou $\alpha = 0.5$ ou  $\beta = 1$ na equação correspondente em (4.5). Tradicionalmente, a medida-F em sua forma balanceada é representada por $\text{\textbf{F}}_{\beta = 1}$, ou simplesmente $\text{\textbf{F}}_{1}$ e possui
a seguinte equação

\begin{equation}
 \text{\textbf{F}}_1 = \dfrac{2\text{\textbf{PC}}}{\text{\textbf{P}} + \text{\textbf{C}}}
\end{equation}

apoś a considerarmos $\beta = 1$. Analogamente, também pode ser feita a substituição do coeficiente $\alpha$ por 0.5 na fórmula à esquerda em (4.5).
Aplicações usando estas métricas serão abordadas no capítulo 6 - Resultados mais adiante.

É digno de menção, a título de curiosidade do leitor, que além das três métricas discutidas aqui, há muitas outras tais como a Acurácia e a Sensibilidade, que são definidas
a partir de outras combinações de numerador e denominador dos valores obtidos de \textbf{VP}, \textbf{VN}, \textbf{FP} e \textbf{FN}. A Acurácia (\textbf{ACC}), por exemplo, é 
definida matematicamente pela seguinte equação:

\begin{equation}
 \text{\textbf{ACC}} = \dfrac{\text{\textbf{VP} + \textbf{VN}}}{\text{\textbf{VP}} + \text{\textbf{VN}} + \text{\textbf{FP}} + \text{\textbf{FN}}}
\end{equation}

No próximo capítulo falaremos um pouco sobre as ferramentas que foram utilizadas para o desenvolvimento do trabalho.

\pagebreak
\chapter{Ferramentas Utilizadas}

\indent\indent Neste capítulo falaremos das ferramentas que foram usadas para que o Córpus anotado fosse contruído e suas entidades mencionadas extraídas
de forma automatizada: BRAT e OpenNLP. É importante ressaltar que este capítulo apenas abordará as funcionalidades das ferramentas que foram utilizadas e desconsiderará todas as
demais. Ainda, também serão apresentados comentários acerca das ferramentas, ressaltando seus pontos fortes e fracos que puderam ser percebidos com o uso delas,
no final das suas respectivas seções.

\section{BRAT}

\indent\indent O BRAT é um projeto \textit{open source} (Licença MIT) recente, desenvolvido colaborativamente por pesquisadores de vários grupos distintos com interesse em
anotações de texto. A ferramenta fornece uma interface limpa e amigável ao usuário para que ele faça anotações rapidamente, de tal forma que
entidades podem ser marcadas apenas com a seleção das \textit{tokens} usando o \textit{mouse} e relacionamentos podem ser criados a partir de um clique e um arrastão do
\textit{mouse} de uma entidade à outra. Assim, com simples ações de mouse o usuário pode rapidamente anotar seus textos sem ter que se preocupar com detalhes tais como
posição de caracteres das \textit{tokens} anotadas e outros.

\subsection{Visualização dos Dados via Browser}

\indent\indent Conforme mencionado na seção anterior, o BRAT é uma ferramenta que fornece uma interface limpa e amigável ao usuário. A maneira que o BRAT encontrou para fazer isso
é via \textit{browser}, com preferência pelo Chrome (Google) e o Safari (Apple) mas dando suporte para alguns outros, conforme pode ser vista na
tabela\footnote[9]{Dados retirados de: http://brat.nlplab.org/supported-browsers.html} abaixo:

\begin{table}[h!]
  \centering
  \def\arraystretch{0.97}
  \begin{tabular}{| c | c | c |}
    \hline
    Browser & Visualização & Edição \\
    \hline\hline
    Chrome (Google) - PC/Mac                      & \cellcolor{strong} & \cellcolor{strong}   \\ \hline
    Safari (Apple) - PC/Mac                       & \cellcolor{strong} & \cellcolor{strong}   \\ \hline
    Firefox (Mozilla)                             & \cellcolor{strong} & \cellcolor{moderate} \\ \hline
    Opera                                         & \cellcolor{strong} & \cellcolor{moderate} \\ \hline
    Internet Explorer (Microsoft) versão 9        & \cellcolor{strong} & \cellcolor{moderate} \\ \hline
    Safari (Apple) - iPad/iPhone                  & \cellcolor{strong} & \cellcolor{moderate} \\ \hline
    Android Browser (Google) Android Tablet/Phone & \cellcolor{strong} & \cellcolor{weak}     \\ \hline
    Internet Explorer (Microsoft) versão $<$ 9    & \cellcolor{weak}   & \cellcolor{weak}     \\ \hline
  \end{tabular}
  \begin{tabular}{| c |}
    \hline
    Total \cellcolor{strong} \\ \hline
    Parcial \cellcolor{moderate} \\ \hline
    Nenhum \cellcolor{weak} \\ \hline
  \end{tabular}
  \caption{Browsers suportados pelo BRAT.}
\end{table}

Na tabela 5.1 acima, a coluna \quotes{Visualização} compreende às funcionalidades de navegação pelas coleções e a mostra das anotações existentes na dada coleção, enquanto
que a coluna de \quotes{Edição} corresponde a criação, deleção e mudança de anotações.Ainda, não é necessário instalar quaisquer \textit{plugins} de \textit{browser}
para poder fazer uso do BRAT. Mais informações podem ser encontradas na página da ferramenta. Imagens de captura de tela serão mostradas em seções adiante.

\subsection{Configurações}

\subsection{Implementação}

\section{OpenNLP}

\pagebreak
\chapter{Resultados}

\pagebreak
\chapter{Conclusão}
\section{Dificuldades encontradas}
\section{Próximo Passo}
\subsection{Aprendizado de Máquina}

\pagebreak
\chapter*{Referências}
\markboth{UNNUMBERED CHAPTER}{}

\begin{enumerate}[label={[\arabic*]}]
\item Acesso à Informação: Conheça o CADE. Disponível em: \textless\enspace http://www.cade.gov.br/acesso-a-informacao/institucional\enspace\textgreater. Acesso em: 13 de outubro de 2016.
\item Assessoria de Comunicação Social. Acesso à Informação: Histórico do CADE. Disponível em: \textless\enspace http://www.cade.gov.br/acesso-a-informacao/institucional/historico-do-cade\enspace\textgreater. Acesso em: 13 de outubro de 2016.
\item Assessoria de Comunicação Social. Perguntas frequentes sobre Atos de Concentração Econômica. Disponível em: \textless\enspace http://www.cade.gov.br/servicos/perguntas-frequentes/perguntas-sobre-atos-de-concentracao-economica\enspace\textgreater. Acesso em: 14 de outubro de 2016.
\item Base de Dados pública do CADE: Pesquisa Processual. Disponível em: \newline\textless\enspace http://www.cade.gov.br/assuntos/processos-1\enspace\textgreater. Acesso em: 14 de outubro de 2016.
\item Documentação OpenNLP: REM. Disponível em: \newline\textless\enspace https://opennlp.apache.org/documentation/manual/opennlp.html\#tools.namefind \enspace\textgreater. Acesso em: 14 de outubro de 2016.
\item CADE. Resolução nº 2, de 29 de maio de 2012. Seção 2, página 3. Disponível em: \textless\enspace http://www.cade.gov.br/assuntos/normas-e-legislacao/resolucao/resolucao-2\_2012-analise-atos-concentracao.pdf \enspace\textgreater. Acesso em: 14 de outubro de 2016.
\item CADE. Resolução nº 2, de 29 de maio de 2012. Anexo I - Formulário Procedimento Não-Sumário. Disponível em: \newline\textless\enspace http://www.cade.gov.br/assuntos/normas-e-legislacao/resolucao/resolucao-2\_2012-analise-atos-concentracao.pdf \enspace\textgreater. Acesso em: 14 de outubro de 2016.
\item CADE. Resolução nº 2, de 29 de maio de 2012. Anexo II - Formulário Procedimento Sumário. Disponível em: \newline\textless\enspace http://www.cade.gov.br/assuntos/normas-e-legislacao/resolucao/resolucao-2\_2012-analise-atos-concentracao.pdf \enspace\textgreater. Acesso em: 14 de outubro de 2016.
\item WIKIPEDIA. Natural Language Processing. Disponível em: \newline\textless\enspace https://en.wikipedia.org/wiki/Natural\_language\_processing \enspace\textgreater. Acesso em: 15 de outubro de 2016.
\item WIKIPEDIA. Brown Corpus. Disponível em: \textless\enspace https://en.wikipedia.org/wiki/Brown\_Corpus \enspace\textgreater. Acesso em: 15 de outubro de 2016.
\item SAMPSON, Geoffrey. The Susanne Corpus. Disponível em: \newline\textless\enspace http://www.essex.ac.uk/linguistics/external/clmt/w3c/corpus\_ling/content/\newline corpora/list/public/susanne.html \enspace\textgreater. Acesso em: 15 de outubro de 2016.
\item MANNING, Christopher D., SCHUETZE, Hinrich. Foundations of Statistical Natural Language Processing, MIT Press. Cambridge, MA: May 1999.
\item LINGUATECA. Corpus Amazônia. Disponível em \textless\enspace http://www.linguateca.pt/floresta/\newline corpus.html\#amazonia \enspace\textgreater. Acesso em: 15 de outrobro de 2016.
\item WIKIPEDIA. Sentence Boundary Disambiguation. Disponível em \newline\textless\enspace https://en.wikipedia.org/wiki/Sentence\_boundary\_disambiguation \enspace\textgreater. Acesso em: 19 de outubro de 2016.
\item INDURKHYA, Nitin., DAMERAU, Fred J., Handbook of Natural Language Processing, Chapman \& Hall/CRC, 2010.
\item CARVALHO, Wesley Seidel. Reconhecimento de entidades mencionadas em português utilizando aprendizado de máquina, São Paulo, 2012
\item WIKIPEDIA. Named Entity. Disponível em: \newline\textless\enspace https://en.wikipedia.org/wiki/Named\_entity \enspace\textgreater. Acesso em: 22 de outubro de 2016.
\item WIKIPEDIA. Named Entity Recognition. Disponível em: \newline\textless\enspace https://en.wikipedia.org/wiki/Named-entity\_recognition \enspace\textgreater. Acesso em: 22 de outubro de 2016.
\item WIKIPEDIA. Gold-standard. Disponível em: \newline\textless\enspace https://en.wikipedia.org/wiki/Gold\_standard\_\%28test\%29 \enspace\textgreater. Acesso em: 23 de outubro de 2016.
\item MANNING, Christopher D., RAGHAVAN, Prabhakar., SCHUETZE, Hinrich. An Introduction to Information Retrieval. Online Edition. Cambridge University Press. 2008.
\item Pontus Stenetorp, Sampo Pyysalo, Goran Topić, Tomoko Ohta, Sophia Ananiadou and Jun'ichi Tsujii (2012). brat: a Web-based Tool for NLP-Assisted Text Annotation. In Proceedings of the Demonstrations Session at EACL 2012.
\end{enumerate}

\end{document}
